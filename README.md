# API for Open LLMs

<p align="center">
    <a href="https://github.com/xusenlinzy/api-for-open-llm"><img src="https://img.shields.io/github/license/xusenlinzy/api-for-open-llm"></a>
    <a href=""><img src="https://img.shields.io/badge/python-3.8+-aff.svg"></a>
    <a href=""><img src="https://img.shields.io/badge/pytorch-%3E=1.14-red?logo=pytorch"></a>
    <a href="https://github.com/xusenlinzy/api-for-open-llm"><img src="https://img.shields.io/github/last-commit/xusenlinzy/api-for-open-llm"></a>
    <a href="https://github.com/xusenlinzy/api-for-open-llm"><img src="https://img.shields.io/github/issues/xusenlinzy/api-for-open-llm?color=9cc"></a>
    <a href="https://github.com/xusenlinzy/api-for-open-llm"><img src="https://img.shields.io/github/stars/xusenlinzy/api-for-open-llm?color=ccf"></a>
    <a href="https://github.com/xusenlinzy/api-for-open-llm"><img src="https://img.shields.io/badge/langurage-py-brightgreen?style=flat&color=blue"></a>
</p>


![llm.png](images/llm.png)
<div align="center"> å›¾ç‰‡æ¥è‡ªäºè®ºæ–‡: [A Survey of Large Language Models](https://arxiv.org/pdf/2303.18223.pdf) </div>


## ğŸ“¢ News 


+ 2023.7.14 æ”¯æŒåœ¨ä¸€ä¸ª `API BASE` ä¸‹è°ƒç”¨å¤šä¸ªæ¨¡å‹ï¼Œä½¿ç”¨æ–¹å¼ï¼šâ‘  æ ¹æ® [SCRIPT.md](./SCRIPT.md) å¯åŠ¨å¤šä¸ªæ¨¡å‹ï¼›â‘¡ ä¿®æ”¹ [chatgpt.py](./chatgpt.py) ä¸­çš„ `MODEL_LIST`ï¼Œå°†å¯åŠ¨çš„æ¨¡å‹åŠ å…¥è¿›å»ï¼›â‘¢ è¿è¡Œ [chatgpt.py](./chatgpt.py)


+ 2023.7.12 æ–°å¢ [baichuan-13b-chat](https://github.com/baichuan-inc/Baichuan-13B)ï¼Œå¯åŠ¨æ–¹å¼è§ [baichuan-13b-chat](https://github.com/xusenlinzy/api-for-open-llm/blob/master/SCRIPT.md#baichuan-13b-chat)


+ 2023.7.7 æ–°å¢ [InternLM](https://github.com/InternLM/InternLM) æ¨¡å‹ï¼Œå¯åŠ¨æ–¹å¼è§ [internlm-chat-7b](https://github.com/xusenlinzy/api-for-open-llm/blob/master/SCRIPT.md#internlm)


+ 2023.6.26 æ–°å¢ [ChatGLM2-6b](https://github.com/THUDM/ChatGLM2-6B) æ¨¡å‹


+ 2023.6.12 ä½¿ç”¨ [m3e](https://huggingface.co/moka-ai/m3e-base) ä¸­æ–‡åµŒå…¥æ¨¡å‹ï¼ˆåœ¨ä¸­æ–‡æ–‡æœ¬åˆ†ç±»å’Œæ–‡æœ¬æ£€ç´¢ä¸Šéƒ½ä¼˜äº `openai-ada-002`ï¼‰


**ä¸»è¦ç‰¹æ€§**ï¼š

æ­¤é¡¹ç›®ä¸ºå¼€æºå¤§æ¨¡å‹çš„æ¨ç†å®ç°ç»Ÿä¸€çš„åç«¯æ¥å£ï¼Œä¸ `OpenAI` çš„å“åº”ä¿æŒä¸€è‡´ï¼Œå…·æœ‰ä»¥ä¸‹ç‰¹æ€§ï¼š

+ âœ¨ ä»¥ `OpenAI ChatGPT API` çš„æ–¹å¼è°ƒç”¨å„ç±»å¼€æºå¤§æ¨¡å‹


+ ğŸ–¨ï¸ æ”¯æŒæµå¼å“åº”ï¼Œå®ç°æ‰“å°æœºæ•ˆæœ


+ ğŸ“– å®ç°æ–‡æœ¬åµŒå…¥æ¨¡å‹ï¼Œä¸ºæ–‡æ¡£çŸ¥è¯†é—®ç­”æä¾›æ”¯æŒ


+ ğŸ¦œï¸ æ”¯æŒå¤§è§„æ¨¡è¯­è¨€æ¨¡å‹å¼€å‘å·¥å…· [`langchain` ](https://github.com/hwchase17/langchain) çš„å„ç±»åŠŸèƒ½
 

+ ğŸ™Œ åªéœ€è¦ç®€å•çš„ä¿®æ”¹ç¯å¢ƒå˜é‡å³å¯å°†å¼€æºæ¨¡å‹ä½œä¸º `chatgpt` çš„æ›¿ä»£æ¨¡å‹ï¼Œä¸ºå„ç±»åº”ç”¨æä¾›åç«¯æ”¯æŒ


+ ğŸš€ æ”¯æŒåŠ è½½ç»è¿‡è‡ªè¡Œè®­ç»ƒè¿‡çš„ `lora` æ¨¡å‹


## ğŸ¼ æ¨¡å‹

æ”¯æŒå¤šç§å¼€æºå¤§æ¨¡å‹

| Model                                                                 |   Backbone   | #Params  | Claimed language |                                               checkpoint link                                               |
|:----------------------------------------------------------------------|:------------:|:--------:|:----------------:|:-----------------------------------------------------------------------------------------------------------:|
| [baichuan-13b-chat](https://github.com/baichuan-inc/Baichuan-13B)     |   Baichuan   |   13B    |      en, zh      |           [baichuan-inc/Baichuan-13B-Chat](https://huggingface.co/baichuan-inc/Baichuan-13B-Chat)           |
| [InternLM](https://github.com/InternLM/InternLM)                      |   InternLM   |    7B    |      en, zh      |                [internlm/internlm-chat-7b](https://huggingface.co/internlm/internlm-chat-7b)                |
| [ChatGLM2](https://github.com/THUDM/ChatGLM2-6B)                      |     GLM      |  6/130B  |      en, zh      |                        [THUDM/chatglm2-6b](https://huggingface.co/THUDM/chatglm2-6b)                        |
| [baichaun-7b](https://github.com/baichuan-inc/baichuan-7B)            |   Baichuan   |    7B    |      en, zh      |                 [baichuan-inc/baichuan-7B](https://huggingface.co/baichuan-inc/baichuan-7B)                 |
| [Guanaco](https://github.com/artidoro/qlora/tree/main)                |    LLaMA     | 7/33/65B |        en        |           [timdettmers/guanaco-33b-merged](https://huggingface.co/timdettmers/guanaco-33b-merged)           |
| [YuLan-Chat](https://github.com/RUC-GSAI/YuLan-Chat)                  |    LLaMA     |  13/65B  |      en, zh      |            [RUCAIBox/YuLan-Chat-13b-delta](https://huggingface.co/RUCAIBox/YuLan-Chat-13b-delta)            |
| [TigerBot](https://github.com/TigerResearch/TigerBot)                 |    BLOOMZ    |  7/180B  |      en, zh      |            [TigerResearch/tigerbot-7b-sft](https://huggingface.co/TigerResearch/tigerbot-7b-sft)            |
| [OpenBuddy](https://github.com/OpenBuddy/OpenBuddy)                   | LLaMAã€Falcon |    7B    |      multi       |                                [OpenBuddy](https://huggingface.co/OpenBuddy)                                |
| [MOSS](https://github.com/OpenLMLab/MOSS)                             |   CodeGen    |   16B    |      en, zh      |              [fnlp/moss-moon-003-sft-int4](https://huggingface.co/fnlp/moss-moon-003-sft-int4)              |
| [Phoenix](https://github.com/FreedomIntelligence/LLMZoo)              |    BLOOMZ    |    7B    |      multi       | [FreedomIntelligence/phoenix-inst-chat-7b](https://huggingface.co/FreedomIntelligence/phoenix-inst-chat-7b) |
| [BAIZE](https://github.com/project-baize/baize-chatbot)               |    LLaMA     | 7/13/30B |        en        |              [project-baize/baize-lora-7B](https://huggingface.co/project-baize/baize-lora-7B)              |
| [Chinese-LLaMA-Alpaca](https://github.com/ymcui/Chinese-LLaMA-Alpaca) |    LLaMA     |  7/13B   |      en, zh      |   [ziqingyang/chinese-alpaca-plus-lora-7b](https://huggingface.co/ziqingyang/chinese-alpaca-plus-lora-7b)   |
| [BELLE](https://github.com/LianjiaTech/BELLE)                         |    BLOOMZ    |    7B    |        zh        |                   [BelleGroup/BELLE-7B-2M](https://huggingface.co/BelleGroup/BELLE-7B-2M)                   |
| [ChatGLM](https://github.com/THUDM/ChatGLM-6B)                        |     GLM      |    6B    |      en, zh      |                         [THUDM/chatglm-6b](https://huggingface.co/THUDM/chatglm-6b)                         |


## ğŸ³ ç¯å¢ƒé…ç½®

### dockerå¯åŠ¨ï¼ˆ**æ¨è**ï¼‰

æ„å»ºé•œåƒ

```shell
docker build -t llm-api:pytorch .
```

å¯åŠ¨å®¹å™¨

```shell
docker run -it -d --gpus all --ipc=host --net=host -p 80:80 --name=chatglm \
    --ulimit memlock=-1 --ulimit stack=67108864 \
    -v `pwd`:/workspace \
    llm-api:pytorch \
    python api/app.py \
    --port 80 \
    --allow-credentials \
    --model_name chatglm \
    --model_path THUDM/chatglm-6b \
    --embedding_name moka-ai/m3e-base
```

ä¸»è¦å‚æ•°å«ä¹‰ï¼š

+ `model_name`: æ¨¡å‹åç§°ï¼Œå¦‚`chatglm`ã€`phoenix`ã€`moss`ç­‰

+ `model_path`: å¼€æºå¤§æ¨¡å‹çš„æ–‡ä»¶æ‰€åœ¨è·¯å¾„

+ `embedding_name`ï¼ˆå¯é€‰é¡¹ï¼‰: åµŒå…¥æ¨¡å‹çš„æ–‡ä»¶æ‰€åœ¨è·¯å¾„

æ›´å¤šæ¨¡å‹çš„å¯åŠ¨å‘½ä»¤è¯¦è§ [SCRIPT.md](./SCRIPT.md)

### æœ¬åœ°å¯åŠ¨

å®‰è£… `pytorch` ç¯å¢ƒ

```shell
conda create -n pytorch python=3.8
conda activate pytorch
conda install pytorch cudatoolkit -c pytorch
```

å®‰è£…ä¾èµ–åŒ…

```shell
pip install -r requirements.txt
```

å¯åŠ¨åç«¯

```shell
python api/app.py \
    --port 80 \
    --allow-credentials \
    --model_path THUDM/chatglm-6b \
    --embedding_name GanymedeNil/text2vec-large-chinese
```


## ğŸ¤– ä½¿ç”¨æ–¹å¼

### ç¯å¢ƒå˜é‡

+ `OPENAI_API_KEY`: æ­¤å¤„éšæ„å¡«ä¸€ä¸ªå­—ç¬¦ä¸²å³å¯

+ `OPENAI_API_BASE`: åç«¯å¯åŠ¨çš„æ¥å£åœ°å€ï¼Œå¦‚ï¼šhttp://192.168.0.xx:80/v1

### [èŠå¤©ç•Œé¢](./applications)

```shell
cd applications

python web_demo.py
```

![chat](images/chat.png)

### [openai-python](https://github.com/openai/openai-python)

<details>
<summary>ğŸ‘‰ Chat Completions</summary>

```python
import openai

openai.api_base = "http://192.168.0.xx:80/v1"

# Enter any non-empty API key to pass the client library's check.
openai.api_key = "xxx"

# Enter any non-empty model name to pass the client library's check.
completion = openai.ChatCompletion.create(
    model="chatglm-6b",
    messages=[
        {"role": "user", "content": "ä½ å¥½"},
    ],
    stream=False,
)

print(completion.choices[0].message.content)
# ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM-6Bï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚
```

</details>

<details>
<summary>ğŸ‘‰ Completions</summary>

```python
import openai

openai.api_base = "http://192.168.0.xx:80/v1"

# Enter any non-empty API key to pass the client library's check.
openai.api_key = "xxx"

# Enter any non-empty model name to pass the client library's check.
completion = openai.Completion.create(prompt="ä½ å¥½", model="chatglm-6b")

print(completion.choices[0].text)
# ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM-6Bï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚
```

</details>

<details>
<summary>ğŸ‘‰ Embeddings</summary>

```python
import openai

openai.api_base = "http://192.168.0.xx:80/v1"

# Enter any non-empty API key to pass the client library's check.
openai.api_key = "xxx"

# compute the embedding of the text
embedding = openai.Embedding.create(
    input="ä»€ä¹ˆæ˜¯chatgptï¼Ÿ", 
    model="text2vec-large-chinese"
)

print(embedding['data'][0]['embedding'])
```

</details>

### [langchain](https://github.com/hwchase17/langchain)

<details>
<summary>ğŸ‘‰ Chat Completions</summary>

```python
import os

os.environ["OPENAI_API_BASE"] = "http://192.168.0.xx:80/v1"
os.environ["OPENAI_API_KEY"] = "xxx"

from langchain.chat_models import ChatOpenAI
from langchain.schema import HumanMessage

chat = ChatOpenAI()
print(chat([HumanMessage(content="ä½ å¥½")]))
# content='ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM-6Bï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚' additional_kwargs={}
```
</details>

<details>
<summary>ğŸ‘‰ Completions</summary>

```python
import os

os.environ["OPENAI_API_BASE"] = "http://192.168.0.xx:80/v1"
os.environ["OPENAI_API_KEY"] = "xxx"

from langchain.llms import OpenAI

llm = OpenAI()
print(llm("ä½ å¥½"))
# ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM-6Bï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚
```

</details>

<details>
<summary>ğŸ‘‰ Embeddings</summary>

```python
import os

os.environ["OPENAI_API_BASE"] = "http://192.168.0.xx:80/v1"
os.environ["OPENAI_API_KEY"] = "xxx"

from langchain.embeddings import OpenAIEmbeddings

embeddings = OpenAIEmbeddings()
query_result = embeddings.embed_query("ä»€ä¹ˆæ˜¯chatgptï¼Ÿ")
print(query_result)
```
</details>

### å¯æ¥å…¥çš„é¡¹ç›®

**é€šè¿‡ä¿®æ”¹ä¸Šé¢çš„ `OPENAI_API_BASE` ç¯å¢ƒå˜é‡ï¼Œå¤§éƒ¨åˆ†çš„ `chatgpt` åº”ç”¨å’Œå‰åç«¯é¡¹ç›®éƒ½å¯ä»¥æ— ç¼è¡”æ¥ï¼**

+ [ChatGPT-Next-Web: One-Click to deploy well-designed ChatGPT web UI on Vercel](https://github.com/Yidadaa/ChatGPT-Next-Web)

```shell
docker run -d -p 3000:3000 \
   -e OPENAI_API_KEY="sk-xxxx" \
   -e BASE_URL="http://192.168.0.xx:80" \
   yidadaa/chatgpt-next-web
```

![web](images/web.png)

+ [dify: An easy-to-use LLMOps platform designed to empower more people to create sustainable, AI-native applications](https://github.com/langgenius/dify)

```shell
# åœ¨docker-compose.ymlä¸­çš„apiå’ŒworkeræœåŠ¡ä¸­æ·»åŠ ä»¥ä¸‹ç¯å¢ƒå˜é‡
OPENAI_API_BASE: http://192.168.0.xx:80/v1
DISABLE_PROVIDER_CONFIG_VALIDATION: 'true'
```

![dify](images/dify.png)


## ğŸ“œ License

æ­¤é¡¹ç›®ä¸º `Apache 2.0` è®¸å¯è¯æˆæƒï¼Œæœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜… [LICENSE](LICENSE) æ–‡ä»¶ã€‚


## ğŸš§ References

+ [ChatGLM: An Open Bilingual Dialogue Language Model](https://github.com/THUDM/ChatGLM-6B)

+ [BLOOM: A 176B-Parameter Open-Access Multilingual Language Model](https://arxiv.org/abs/2211.05100)

+ [LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/abs/2302.13971v1)

+ [Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca](https://github.com/ymcui/Chinese-LLaMA-Alpaca)

+ [Phoenix: Democratizing ChatGPT across Languages](https://github.com/FreedomIntelligence/LLMZoo)

+ [MOSS: An open-sourced plugin-augmented conversational language model](https://github.com/OpenLMLab/MOSS)

+ [FastChat: An open platform for training, serving, and evaluating large language model based chatbots](https://github.com/lm-sys/FastChat)

+ [LangChain: Building applications with LLMs through composability](https://github.com/hwchase17/langchain)

+ [ChuanhuChatgpt](https://github.com/GaiZhenbiao/ChuanhuChatGPT)
