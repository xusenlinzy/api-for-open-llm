# API for Open LLMs

<p align="center">
    <a href="https://github.com/xusenlinzy/api-for-open-llm"><img src="https://img.shields.io/github/license/xusenlinzy/api-for-open-llm"></a>
    <a href=""><img src="https://img.shields.io/badge/python-3.8+-aff.svg"></a>
    <a href=""><img src="https://img.shields.io/badge/pytorch-%3E=1.14-red?logo=pytorch"></a>
    <a href="https://github.com/xusenlinzy/api-for-open-llm"><img src="https://img.shields.io/github/last-commit/xusenlinzy/api-for-open-llm"></a>
    <a href="https://github.com/xusenlinzy/api-for-open-llm"><img src="https://img.shields.io/github/issues/xusenlinzy/api-for-open-llm?color=9cc"></a>
    <a href="https://github.com/xusenlinzy/api-for-open-llm"><img src="https://img.shields.io/github/stars/xusenlinzy/api-for-open-llm?color=ccf"></a>
    <a href="https://github.com/xusenlinzy/api-for-open-llm"><img src="https://img.shields.io/badge/langurage-py-brightgreen?style=flat&color=blue"></a>
</p>

æ­¤é¡¹ç›®ä¸ºå¼€æºå¤§æ¨¡å‹çš„æ¨ç†å®ç°ç»Ÿä¸€çš„åç«¯æ¥å£ï¼Œä¸ `OpenAI` çš„å“åº”ä¿æŒä¸€è‡´ï¼Œå…·æœ‰ä»¥ä¸‹ç‰¹æ€§ï¼š

+ âœ¨ ä»¥ `OpenAI ChatGPT API` çš„æ–¹å¼è°ƒç”¨å„ç±»å¼€æºå¤§æ¨¡å‹


+ ğŸ–¨ï¸ æ”¯æŒæµå¼å“åº”ï¼Œå®ç°æ‰“å°æœºæ•ˆæœ


+ ğŸ“– å®ç°æ–‡æœ¬åµŒå…¥æ¨¡å‹ï¼Œä¸ºæ–‡æ¡£çŸ¥è¯†é—®ç­”æä¾›æ”¯æŒ


+ ğŸ¦œï¸ æ”¯æŒå¤§è§„æ¨¡è¯­è¨€æ¨¡å‹å¼€å‘å·¥å…· [`langchain` ](https://github.com/hwchase17/langchain) çš„å„ç±»åŠŸèƒ½
 

+ ğŸ™Œ åªéœ€è¦ç®€å•çš„ä¿®æ”¹ç¯å¢ƒå˜é‡å³å¯å°†å¼€æºæ¨¡å‹ä½œä¸º `chatgpt` çš„æ›¿ä»£æ¨¡å‹ï¼Œä¸ºå„ç±»åº”ç”¨æä¾›åç«¯æ”¯æŒ


+ ğŸš€ æ”¯æŒåŠ è½½ç»è¿‡è‡ªè¡Œè®­ç»ƒè¿‡çš„ `lora` æ¨¡å‹

---

## ğŸ¼ æ¨¡å‹

æ”¯æŒå¤šç§å¼€æºå¤§æ¨¡å‹

| Model                                                                 | Backbone | #Params  | Claimed language | Instruction-training | Conversation-training |                                               checkpoint link                                               |
|:----------------------------------------------------------------------|:--------:|:--------:|:----------------:|:--------------------:|:---------------------:|:-----------------------------------------------------------------------------------------------------------:|
| [ChatGLM](https://github.com/THUDM/ChatGLM-6B)                        |   GLM    |    6B    |      en, zh      |                      |                       |                         [THUDM/chatglm-6b](https://huggingface.co/THUDM/chatglm-6b)                         |
| [BELLE](https://github.com/LianjiaTech/BELLE)                         |  BLOOMZ  |    7B    |        zh        |       1.5M, zh       |           âŒ           |                   [BelleGroup/BELLE-7B-2M](https://huggingface.co/BelleGroup/BELLE-7B-2M)                   |
| [Chinese-LLaMA-Alpaca](https://github.com/ymcui/Chinese-LLaMA-Alpaca) |  LLaMA   |  7/13B   |      en, zh      |     2M/3M, en/zh     |           âŒ           |   [ziqingyang/chinese-alpaca-plus-lora-7b](https://huggingface.co/ziqingyang/chinese-alpaca-plus-lora-7b)   |
| [BAIZE](https://github.com/project-baize/baize-chatbot)               |  LLaMA   | 7/13/30B |        en        |          âŒ           |      111.5K, en       |              [project-baize/baize-lora-7B](https://huggingface.co/project-baize/baize-lora-7B)              |
| [Phoenix](https://github.com/FreedomIntelligence/LLMZoo)              |  BLOOMZ  |    7B    |      multi       |         40+          |          40+          | [FreedomIntelligence/phoenix-inst-chat-7b](https://huggingface.co/FreedomIntelligence/phoenix-inst-chat-7b) |
| [MOSS](https://github.com/OpenLMLab/MOSS)                             | CodeGen  |   16B    |      en, zh      |                      |                       |              [fnlp/moss-moon-003-sft-int4](https://huggingface.co/fnlp/moss-moon-003-sft-int4)              |
| [Guanaco](https://github.com/artidoro/qlora/tree/main)                |  LLaMA   | 7/33/65B |        en        |                      |                       |           [timdettmers/guanaco-33b-merged](https://huggingface.co/timdettmers/guanaco-33b-merged)           |


## ğŸ³ ç¯å¢ƒé…ç½®

### dockerå¯åŠ¨ï¼ˆ**æ¨è**ï¼‰

æ„å»ºé•œåƒ

```shell
docker build -t llm-api:pytorch .
```

å¯åŠ¨å®¹å™¨

```shell
docker run -it -d --gpus all --ipc=host --net=host -p 80:80 --name=chatglm \
    --ulimit memlock=-1 --ulimit stack=67108864 \
    -v `pwd`:/workspace \
    llm-api:pytorch \
    python api/app.py \
    --port 80 \
    --allow-credentials \
    --model_name chatglm \
    --model_path THUDM/chatglm-6b \
    --embedding_name GanymedeNil/text2vec-large-chinese
```

ä¸»è¦å‚æ•°å«ä¹‰ï¼š

+ `model_name`: æ¨¡å‹åç§°ï¼Œå¦‚`chatglm`ã€`phoenix`ã€`moss`ç­‰

+ `model_path`: å¼€æºå¤§æ¨¡å‹çš„æ–‡ä»¶æ‰€åœ¨è·¯å¾„

+ `embedding_name`ï¼ˆå¯é€‰é¡¹ï¼‰: åµŒå…¥æ¨¡å‹çš„æ–‡ä»¶æ‰€åœ¨è·¯å¾„

### æœ¬åœ°å¯åŠ¨

å®‰è£… `pytorch` ç¯å¢ƒ

```shell
conda create -n pytorch python=3.8
conda activate pytorch
conda install pytorch cudatoolkit -c pytorch
```

å®‰è£…ä¾èµ–åŒ…

```shell
pip install -r requirements.txt
```

å¯åŠ¨åç«¯

```shell
python api/app.py \
    --port 80 \
    --allow-credentials \
    --model_path THUDM/chatglm-6b \
    --embedding_name GanymedeNil/text2vec-large-chinese
```


## ğŸ¤– ä½¿ç”¨æ–¹å¼

### ç¯å¢ƒå˜é‡

+ `OPENAI_API_KEY`: æ­¤å¤„éšæ„å¡«ä¸€ä¸ªå­—ç¬¦ä¸²å³å¯

+ `OPENAI_API_BASE`: åç«¯å¯åŠ¨çš„æ¥å£åœ°å€ï¼Œå¦‚ï¼šhttp://192.168.0.xx:80/v1

### [å‘½ä»¤ç«¯å¯åŠ¨å¤šè½®å¯¹è¯](applications/general_chat/client.py)

```shell
cd applications/chat

python client.py --api_base http://192.168.0.xx:80/v1 --model_name chatglm
```

![chat](images/chat.png)

### [openai-python](https://github.com/openai/openai-python)

#### 1. Chat Completions

```python
import openai

openai.api_base = "http://192.168.0.xx:80/v1"

# Enter any non-empty API key to pass the client library's check.
openai.api_key = "xxx"

# Enter any non-empty model name to pass the client library's check.
completion = openai.ChatCompletion.create(
    model="chatglm-6b",
    messages=[
        {"role": "user", "content": "ä½ å¥½"},
    ],
    stream=False,
)

print(completion.choices[0].message.content)
# ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM-6Bï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚
```

#### 2. Completions

```python
import openai

openai.api_base = "http://192.168.0.xx:80/v1"

# Enter any non-empty API key to pass the client library's check.
openai.api_key = "xxx"

# Enter any non-empty model name to pass the client library's check.
completion = openai.Completion.create(prompt="ä½ å¥½", model="chatglm-6b")

print(completion.choices[0].text)
# ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM-6Bï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚
```

#### 3. Embeddings

```python
import openai

openai.api_base = "http://192.168.0.xx:80/v1"

# Enter any non-empty API key to pass the client library's check.
openai.api_key = "xxx"

# compute the embedding of the text
embedding = openai.Embedding.create(
    input="ä»€ä¹ˆæ˜¯chatgptï¼Ÿ", 
    model="text2vec-large-chinese"
)

print(embedding['data'][0]['embedding'])
```

### [langchain](https://github.com/hwchase17/langchain)

#### 1. Chat Completions

```python
import os

os.environ["OPENAI_API_BASE"] = "http://192.168.0.xx:80/v1"
os.environ["OPENAI_API_KEY"] = "xxx"

from langchain.chat_models import ChatOpenAI
from langchain.schema import HumanMessage

chat = ChatOpenAI()
print(chat([HumanMessage(content="ä½ å¥½")]))
# content='ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM-6Bï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚' additional_kwargs={}
```

#### 2. Completions

```python
import os

os.environ["OPENAI_API_BASE"] = "http://192.168.0.xx:80/v1"
os.environ["OPENAI_API_KEY"] = "xxx"

from langchain.llms import OpenAI

llm = OpenAI()
print(llm("ä½ å¥½"))
# ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM-6Bï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚
```

#### 3. Embeddings

```python
import os

os.environ["OPENAI_API_BASE"] = "http://192.168.0.xx:80/v1"
os.environ["OPENAI_API_KEY"] = "xxx"

from langchain.embeddings import OpenAIEmbeddings

embeddings = OpenAIEmbeddings()
query_result = embeddings.embed_query("ä»€ä¹ˆæ˜¯chatgptï¼Ÿ")
print(query_result)
```

### å¯æ¥å…¥çš„é¡¹ç›®

**é€šè¿‡ä¿®æ”¹ä¸Šé¢çš„ `OPENAI_API_BASE` ç¯å¢ƒå˜é‡ï¼Œå¤§éƒ¨åˆ†çš„ `chatgpt` åº”ç”¨å’Œå‰åç«¯é¡¹ç›®éƒ½å¯ä»¥æ— ç¼è¡”æ¥ï¼**

+ [ChatGPT-Next-Web: One-Click to deploy well-designed ChatGPT web UI on Vercel](https://github.com/Yidadaa/ChatGPT-Next-Web)

```shell
docker run -d -p 3000:3000 \
   -e OPENAI_API_KEY="sk-xxxx" \
   -e BASE_URL="http://192.168.0.xx:80" \
   yidadaa/chatgpt-next-web
```

![web](images/web.png)

+ [dify: An easy-to-use LLMOps platform designed to empower more people to create sustainable, AI-native applications](https://github.com/langgenius/dify)

![dify](images/dify.png)


## ğŸ“œ License

æ­¤é¡¹ç›®ä¸º `Apache 2.0` è®¸å¯è¯æˆæƒï¼Œæœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜… [LICENSE](LICENSE) æ–‡ä»¶ã€‚


## ğŸš§ References

[1]: [ChatGLM: An Open Bilingual Dialogue Language Model](https://github.com/THUDM/ChatGLM-6B)

[2]: [BLOOM: A 176B-Parameter Open-Access Multilingual Language Model](https://arxiv.org/abs/2211.05100)

[3]: [LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/abs/2302.13971v1)

[4]: [Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca](https://github.com/ymcui/Chinese-LLaMA-Alpaca)

[5]: [Phoenix: Democratizing ChatGPT across Languages](https://github.com/FreedomIntelligence/LLMZoo)

[6]: [MOSS: An open-sourced plugin-augmented conversational language model](https://github.com/OpenLMLab/MOSS)

[7]: [FastChat: An open platform for training, serving, and evaluating large language model based chatbots](https://github.com/lm-sys/FastChat)

[8]: [LangChain: Building applications with LLMs through composability](https://github.com/hwchase17/langchain)
