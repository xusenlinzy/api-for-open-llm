# API for Open LLMs

<p align="center">
    <a href="https://github.com/xusenlinzy/api-for-open-llm"><img src="https://img.shields.io/github/license/xusenlinzy/api-for-open-llm"></a>
    <a href=""><img src="https://img.shields.io/badge/python-3.8+-aff.svg"></a>
    <a href=""><img src="https://img.shields.io/badge/pytorch-%3E=1.14-red?logo=pytorch"></a>
    <a href="https://github.com/xusenlinzy/api-for-open-llm"><img src="https://img.shields.io/github/last-commit/xusenlinzy/api-for-open-llm"></a>
    <a href="https://github.com/xusenlinzy/api-for-open-llm"><img src="https://img.shields.io/github/issues/xusenlinzy/api-for-open-llm?color=9cc"></a>
    <a href="https://github.com/xusenlinzy/api-for-open-llm"><img src="https://img.shields.io/github/stars/xusenlinzy/api-for-open-llm?color=ccf"></a>
    <a href="https://github.com/xusenlinzy/api-for-open-llm"><img src="https://img.shields.io/badge/langurage-py-brightgreen?style=flat&color=blue"></a>
</p>


![llm.png](images/llm.png)
<div align="center"> å›¾ç‰‡æ¥è‡ªäºè®ºæ–‡: [A Survey of Large Language Models](https://arxiv.org/pdf/2303.18223.pdf) </div>

  
## ğŸ§ QQäº¤æµç¾¤ï¼š870207830


## ğŸ“¢ æ–°é—»

+ ã€2024.02.26ã€‘ QWEN2 æ¨¡å‹éœ€è¦ä¿®æ”¹ç¯å¢ƒå˜é‡ `MODEL_NAME=qwen2`  `PROMPT_NAME=qwen2`

+ ã€2024.01.19ã€‘ æ·»åŠ  [InternLM2](https://github.com/InternLM/InternLM) æ¨¡å‹æ”¯æŒï¼Œ[å¯åŠ¨æ–¹å¼](https://github.com/xusenlinzy/api-for-open-llm/blob/master/docs/SCRIPT.md#internlm2)


+ ã€2023.12.21ã€‘ æ·»åŠ  [TGI](https://github.com/huggingface/text-generation-inference) ç”Ÿæˆæ¥å£è½¬å‘å’Œ [TEI](https://github.com/huggingface/text-embeddings-inference) embedding æ¥å£è½¬å‘


+ ã€2023.12.06ã€‘ æ·»åŠ  [SUS-Chat-34B](https://huggingface.co/SUSTech/SUS-Chat-34B) æ¨¡å‹æ”¯æŒï¼Œ[å¯åŠ¨æ–¹å¼é“¾æ¥](https://github.com/xusenlinzy/api-for-open-llm/blob/master/docs/SCRIPT.md#suschat)


+ ã€2023.11.24ã€‘ æ”¯æŒ [llama-cpp-python](https://github.com/abetlen/llama-cpp-python) æ¨ç†ï¼Œ[ä½¿ç”¨æ–‡æ¡£](https://github.com/xusenlinzy/api-for-open-llm/blob/master/docs/LLAMA_CPP.md)


+ ã€2023.11.03ã€‘ æ”¯æŒ `chatglm3` å’Œ `qwen` æ¨¡å‹çš„ `function call` è°ƒç”¨åŠŸèƒ½ï¼ŒåŒæ—¶æ”¯æŒæµå¼å’Œéæµå¼æ¨¡å¼, [å·¥å…·ä½¿ç”¨ç¤ºä¾‹](https://github.com/xusenlinzy/api-for-open-llm/tree/master/examples/chatglm3/tool_using.py), ç½‘é¡µ `demo` å·²ç»é›†æˆåˆ° [streamlit-demo](./streamlit-demo)


+ ã€2023.10.29ã€‘ æ·»åŠ  [ChatGLM3](https://github.com/THUDM/ChatGLM3) æ¨¡å‹æ”¯æŒï¼Œ[å¯åŠ¨æ–¹å¼é“¾æ¥](https://github.com/xusenlinzy/api-for-open-llm/blob/master/docs/SCRIPT.md#chatglm3)ï¼Œ[å·¥å…·ä½¿ç”¨ç¤ºä¾‹](https://github.com/xusenlinzy/api-for-open-llm/tree/master/examples/chatglm3)


+ ã€2023.09.27ã€‘ æ·»åŠ  [Qwen-14B-Chat-Int4](https://huggingface.co/Qwen/Qwen-14B-Chat-Int4) æ¨¡å‹æ”¯æŒï¼Œ[å¯åŠ¨æ–¹å¼é“¾æ¥](https://github.com/xusenlinzy/api-for-open-llm/blob/master/docs/SCRIPT.md#qwen-14b-chat)


+ ã€2023.09.07ã€‘ æ·»åŠ  [baichuan2](https://github.com/baichuan-inc/Baichuan2) æ¨¡å‹æ”¯æŒï¼Œ[å¯åŠ¨æ–¹å¼é“¾æ¥](https://github.com/xusenlinzy/api-for-open-llm/blob/master/docs/SCRIPT.md#baichuan2)


+ ã€2023.08.28ã€‘ æ·»åŠ  `transformers.TextIteratorStreamer` æµå¼è¾“å‡ºæ”¯æŒï¼Œåªéœ€å°†ç¯å¢ƒå˜é‡ä¿®æ”¹ä¸º `USE_STREAMER_V2=true`


+ ã€2023.08.26ã€‘ æ·»åŠ  [code-llama](https://github.com/facebookresearch/codellama) æ¨¡å‹æ”¯æŒï¼Œ[å¯åŠ¨æ–¹å¼é“¾æ¥](https://github.com/xusenlinzy/api-for-open-llm/blob/master/docs/SCRIPT.md#code-llama)ï¼Œ[ä½¿ç”¨ç¤ºä¾‹é“¾æ¥](https://github.com/xusenlinzy/api-for-open-llm/tree/master/examples/code-llama)


+ ã€2023.08.23ã€‘ æ·»åŠ  [sqlcoder](https://huggingface.co/defog/sqlcoder) æ¨¡å‹æ”¯æŒï¼Œ[å¯åŠ¨æ–¹å¼é“¾æ¥](https://github.com/xusenlinzy/api-for-open-llm/blob/master/docs/SCRIPT.md#sqlcoder)ï¼Œ[ä½¿ç”¨ç¤ºä¾‹é“¾æ¥](https://github.com/xusenlinzy/api-for-open-llm/blob/master/examples/sqlcoder/inference.py)


+ ã€2023.08.22ã€‘ æ·»åŠ  [xverse-13b-chat](https://github.com/xverse-ai/XVERSE-13B) æ¨¡å‹æ”¯æŒï¼Œ[å¯åŠ¨æ–¹å¼é“¾æ¥](https://github.com/xusenlinzy/api-for-open-llm/blob/master/docs/SCRIPT.md#xverse-13b-chat)


+ ã€2023.08.10ã€‘ æ·»åŠ  [vLLM](https://github.com/vllm-project/vllm) æ¨ç†åŠ é€Ÿæ”¯æŒï¼Œ[ä½¿ç”¨æ–‡æ¡£](https://github.com/xusenlinzy/api-for-open-llm/blob/master/docs/VLLM_SCRIPT.md)


+ ã€2023.08.03ã€‘ æ·»åŠ  [qwen-7b-chat](https://github.com/QwenLM/Qwen-7B) æ¨¡å‹æ”¯æŒï¼Œ[å¯åŠ¨æ–¹å¼é“¾æ¥](https://github.com/xusenlinzy/api-for-open-llm/blob/master/docs/SCRIPT.md#qwen-7b-chat)


æ›´å¤šæ–°é—»å’Œå†å²è¯·è½¬è‡³ [æ­¤å¤„](https://github.com/xusenlinzy/api-for-open-llm/blob/master/docs/NEWS.md)

---

**æ­¤é¡¹ç›®ä¸»è¦å†…å®¹**

æ­¤é¡¹ç›®ä¸ºå¼€æºå¤§æ¨¡å‹çš„æ¨ç†å®ç°ç»Ÿä¸€çš„åç«¯æ¥å£ï¼Œä¸ `OpenAI` çš„å“åº”ä¿æŒä¸€è‡´ï¼Œå…·æœ‰ä»¥ä¸‹ç‰¹æ€§ï¼š

+ âœ¨ ä»¥ `OpenAI ChatGPT API` çš„æ–¹å¼è°ƒç”¨å„ç±»å¼€æºå¤§æ¨¡å‹


+ ğŸ–¨ï¸ æ”¯æŒæµå¼å“åº”ï¼Œå®ç°æ‰“å°æœºæ•ˆæœ


+ ğŸ“– å®ç°æ–‡æœ¬åµŒå…¥æ¨¡å‹ï¼Œä¸ºæ–‡æ¡£çŸ¥è¯†é—®ç­”æä¾›æ”¯æŒ


+ ğŸ¦œï¸ æ”¯æŒå¤§è§„æ¨¡è¯­è¨€æ¨¡å‹å¼€å‘å·¥å…· [`langchain` ](https://github.com/hwchase17/langchain) çš„å„ç±»åŠŸèƒ½
 

+ ğŸ™Œ åªéœ€è¦ç®€å•çš„ä¿®æ”¹ç¯å¢ƒå˜é‡å³å¯å°†å¼€æºæ¨¡å‹ä½œä¸º `chatgpt` çš„æ›¿ä»£æ¨¡å‹ï¼Œä¸ºå„ç±»åº”ç”¨æä¾›åç«¯æ”¯æŒ


+ ğŸš€ æ”¯æŒåŠ è½½ç»è¿‡è‡ªè¡Œè®­ç»ƒè¿‡çš„ `lora` æ¨¡å‹


+ âš¡ æ”¯æŒ [vLLM](https://github.com/vllm-project/vllm) æ¨ç†åŠ é€Ÿå’Œå¤„ç†å¹¶å‘è¯·æ±‚


## å†…å®¹å¯¼å¼•

|                                               ç« èŠ‚                                                |              æè¿°               |
|:-----------------------------------------------------------------------------------------------:|:-----------------------------:|
|               [ğŸ’ğŸ»â€â™‚æ”¯æŒæ¨¡å‹](https://github.com/xusenlinzy/api-for-open-llm#-æ”¯æŒæ¨¡å‹)                |       æ­¤é¡¹ç›®æ”¯æŒçš„å¼€æºæ¨¡å‹ä»¥åŠç®€è¦ä¿¡æ¯        |
|       [ğŸš„å¯åŠ¨æ–¹å¼](https://github.com/xusenlinzy/api-for-open-llm/blob/master/docs/SCRIPT.md)       |        å¯åŠ¨æ¨¡å‹çš„ç¯å¢ƒé…ç½®å’Œå¯åŠ¨å‘½ä»¤         |
|   [âš¡vLLMå¯åŠ¨æ–¹å¼](https://github.com/xusenlinzy/api-for-open-llm/blob/master/docs/VLLM_SCRIPT.md)   |   ä½¿ç”¨ `vLLM` å¯åŠ¨æ¨¡å‹çš„ç¯å¢ƒé…ç½®å’Œå¯åŠ¨å‘½ä»¤    |
| [ğŸ¦™llama-cppå¯åŠ¨æ–¹å¼](https://github.com/xusenlinzy/api-for-open-llm/blob/master/docs/LLAMA_CPP.md) | ä½¿ç”¨ `llama-cpp` å¯åŠ¨æ¨¡å‹çš„ç¯å¢ƒé…ç½®å’Œå¯åŠ¨å‘½ä»¤ |
|                 [ğŸ’»è°ƒç”¨æ–¹å¼](https://github.com/xusenlinzy/api-for-open-llm#-ä½¿ç”¨æ–¹å¼)                  |          å¯åŠ¨æ¨¡å‹ä¹‹åçš„è°ƒç”¨æ–¹å¼          |
|         [â“å¸¸è§é—®é¢˜](https://github.com/xusenlinzy/api-for-open-llm/blob/master/docs/FAQ.md)         |           ä¸€äº›å¸¸è§é—®é¢˜çš„å›å¤           |
|     [ğŸ“šç›¸å…³èµ„æº](https://github.com/xusenlinzy/api-for-open-llm/blob/master/docs/RESOURCES.md)      |       å…³äºå¼€æºæ¨¡å‹è®­ç»ƒå’Œæ¨ç†çš„ç›¸å…³èµ„æº        |


## ğŸ¼ æ”¯æŒæ¨¡å‹

**è¯­è¨€æ¨¡å‹**

|                                  æ¨¡å‹                                   |     åŸºåº§æ¨¡å‹     |   å‚æ•°é‡    |   è¯­è¨€   |                                                   æ¨¡å‹æƒé‡é“¾æ¥                                                    |
|:---------------------------------------------------------------------:|:------------:|:--------:|:------:|:-----------------------------------------------------------------------------------------------------------:|
|        [baichuan2](https://github.com/baichuan-inc/Baichuan2)         |   Baichuan   |   7/13   | en, zh |          [baichuan-inc/Baichuan2-13B-Chat](https://huggingface.co/baichuan-inc/Baichuan2-13B-Chat)          |
|      [codellama](https://github.com/facebookresearch/codellama)       |    LLaMA2    | 7/13/34B | multi  |       [codellama/CodeLlama-7b-Instruct-hf](https://huggingface.co/codellama/CodeLlama-7b-Instruct-hf)       |
|      [xverse-13b-chat](https://github.com/xverse-ai/XVERSE-13B)       |    Xverse    |   13B    | multi  |                   [xverse/XVERSE-13B-Chat](https://huggingface.co/xverse/XVERSE-13B-Chat)                   |
|           [qwen-7b-chat](https://github.com/QwenLM/Qwen-7B)           |     Qwen     |    7B    | en, zh |                 [Qwen/Qwen-7B-Chat](https://huggingface.co/baichuan-inc/Qwen/Qwen-7B-Chat)                  |
|   [baichuan-13b-chat](https://github.com/baichuan-inc/Baichuan-13B)   |   Baichuan   |   13B    | en, zh |           [baichuan-inc/Baichuan-13B-Chat](https://huggingface.co/baichuan-inc/Baichuan-13B-Chat)           |
|           [InternLM](https://github.com/InternLM/InternLM)            |   InternLM   |    7B    | en, zh |                [internlm/internlm-chat-7b](https://huggingface.co/internlm/internlm-chat-7b)                |
|           [InternLM2](https://github.com/InternLM/InternLM)           |  InternLM2   |   20B    | en, zh |        [internlm/internlm2-chat-20b](https://huggingface.co/internlm/internlm2-chat-20b)                    |
|           [ChatGLM2](https://github.com/THUDM/ChatGLM2-6B)            |     GLM      |  6/130B  | en, zh |                        [THUDM/chatglm2-6b](https://huggingface.co/THUDM/chatglm2-6b)                        |
|      [baichaun-7b](https://github.com/baichuan-inc/baichuan-7B)       |   Baichuan   |    7B    | en, zh |                 [baichuan-inc/baichuan-7B](https://huggingface.co/baichuan-inc/baichuan-7B)                 |
|        [Guanaco](https://github.com/artidoro/qlora/tree/main)         |    LLaMA     | 7/33/65B |   en   |           [timdettmers/guanaco-33b-merged](https://huggingface.co/timdettmers/guanaco-33b-merged)           |
|         [YuLan-Chat](https://github.com/RUC-GSAI/YuLan-Chat)          |    LLaMA     |  13/65B  | en, zh |            [RUCAIBox/YuLan-Chat-13b-delta](https://huggingface.co/RUCAIBox/YuLan-Chat-13b-delta)            |
|         [TigerBot](https://github.com/TigerResearch/TigerBot)         |    BLOOMZ    |  7/180B  | en, zh |            [TigerResearch/tigerbot-7b-sft](https://huggingface.co/TigerResearch/tigerbot-7b-sft)            |
|          [OpenBuddy](https://github.com/OpenBuddy/OpenBuddy)          | LLaMAã€Falcon |    7B    | multi  |                                [OpenBuddy](https://huggingface.co/OpenBuddy)                                |
|               [MOSS](https://github.com/OpenLMLab/MOSS)               |   CodeGen    |   16B    | en, zh |              [fnlp/moss-moon-003-sft-int4](https://huggingface.co/fnlp/moss-moon-003-sft-int4)              |
|       [Phoenix](https://github.com/FreedomIntelligence/LLMZoo)        |    BLOOMZ    |    7B    | multi  | [FreedomIntelligence/phoenix-inst-chat-7b](https://huggingface.co/FreedomIntelligence/phoenix-inst-chat-7b) |
|        [BAIZE](https://github.com/project-baize/baize-chatbot)        |    LLaMA     | 7/13/30B |   en   |              [project-baize/baize-lora-7B](https://huggingface.co/project-baize/baize-lora-7B)              |
| [Chinese-LLaMA-Alpaca](https://github.com/ymcui/Chinese-LLaMA-Alpaca) |    LLaMA     |  7/13B   | en, zh |   [ziqingyang/chinese-alpaca-plus-lora-7b](https://huggingface.co/ziqingyang/chinese-alpaca-plus-lora-7b)   |
|             [BELLE](https://github.com/LianjiaTech/BELLE)             |    BLOOMZ    |    7B    |   zh   |                   [BelleGroup/BELLE-7B-2M](https://huggingface.co/BelleGroup/BELLE-7B-2M)                   |
|            [ChatGLM](https://github.com/THUDM/ChatGLM-6B)             |     GLM      |    6B    | en, zh |                         [THUDM/chatglm-6b](https://huggingface.co/THUDM/chatglm-6b)                         |


**åµŒå…¥æ¨¡å‹**

|           æ¨¡å‹           |  ç»´åº¦  |                                        æƒé‡é“¾æ¥                                         |
|:----------------------:|:----:|:-----------------------------------------------------------------------------------:|
|      bge-large-zh      | 1024 |              [bge-large-zh](https://huggingface.co/BAAI/bge-large-zh)               |
|       m3e-large        | 1024 |            [moka-ai/m3e-large](https://huggingface.co/moka-ai/m3e-large)            |
| text2vec-large-chinese | 1024 | [text2vec-large-chinese](https://huggingface.co/GanymedeNil/text2vec-large-chinese) |


## ğŸ¤– ä½¿ç”¨æ–¹å¼

### ç¯å¢ƒå˜é‡

+ `OPENAI_API_KEY`: æ­¤å¤„éšæ„å¡«ä¸€ä¸ªå­—ç¬¦ä¸²å³å¯

+ `OPENAI_API_BASE`: åç«¯å¯åŠ¨çš„æ¥å£åœ°å€ï¼Œå¦‚ï¼šhttp://192.168.0.xx:80/v1


### [èŠå¤©ç•Œé¢](./applications)

```shell
cd streamlit-demo
pip install -r requirements.txt
streamlit run streamlit_app.py
```

![img.png](images/demo.png)

### [openai v1.1.0](https://github.com/openai/openai-python)

<details>
<summary>ğŸ‘‰ Chat Completions</summary>

```python
from openai import OpenAI

client = OpenAI(
    api_key="EMPTY",
    base_url="http://192.168.20.59:7891/v1/",
)

# Chat completion API
chat_completion = client.chat.completions.create(
    messages=[
        {
            "role": "user",
            "content": "ä½ å¥½",
        }
    ],
    model="gpt-3.5-turbo",
)
print(chat_completion)
# ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM3-6Bï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚


# stream = client.chat.completions.create(
#     messages=[
#         {
#             "role": "user",
#             "content": "æ„Ÿå†’äº†æ€ä¹ˆåŠ",
#         }
#     ],
#     model="gpt-3.5-turbo",
#     stream=True,
# )
# for part in stream:
#     print(part.choices[0].delta.content or "", end="", flush=True)
```

</details>

<details>
<summary>ğŸ‘‰ Completions</summary>

```python
from openai import OpenAI

client = OpenAI(
    api_key="EMPTY",
    base_url="http://192.168.20.59:7891/v1/",
)


# Chat completion API
completion = client.completions.create(
    model="gpt-3.5-turbo",
    prompt="ä½ å¥½",
)
print(completion)
# ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM-6Bï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚
```

</details>

<details>
<summary>ğŸ‘‰ Embeddings</summary>

```python
from openai import OpenAI

client = OpenAI(
    api_key="EMPTY",
    base_url="http://192.168.20.59:7891/v1/",
)


# compute the embedding of the text
embedding = client.embeddings.create(
    input="ä½ å¥½",
    model="text-embedding-ada-002"
)
print(embedding)

```

</details>


### å¯æ¥å…¥çš„é¡¹ç›®

**é€šè¿‡ä¿®æ”¹ `OPENAI_API_BASE` ç¯å¢ƒå˜é‡ï¼Œå¤§éƒ¨åˆ†çš„ `chatgpt` åº”ç”¨å’Œå‰åç«¯é¡¹ç›®éƒ½å¯ä»¥æ— ç¼è¡”æ¥ï¼**

+ [ChatGPT-Next-Web: One-Click to deploy well-designed ChatGPT web UI on Vercel](https://github.com/Yidadaa/ChatGPT-Next-Web)

```shell
docker run -d -p 3000:3000 \
   -e OPENAI_API_KEY="sk-xxxx" \
   -e BASE_URL="http://192.168.0.xx:80" \
   yidadaa/chatgpt-next-web
```

![web](images/web.png)

+ [dify: An easy-to-use LLMOps platform designed to empower more people to create sustainable, AI-native applications](https://github.com/langgenius/dify)

```shell
# åœ¨docker-compose.ymlä¸­çš„apiå’ŒworkeræœåŠ¡ä¸­æ·»åŠ ä»¥ä¸‹ç¯å¢ƒå˜é‡
OPENAI_API_BASE: http://192.168.0.xx:80/v1
DISABLE_PROVIDER_CONFIG_VALIDATION: 'true'
```

![dify](images/dify.png)


## ğŸ“œ License

æ­¤é¡¹ç›®ä¸º `Apache 2.0` è®¸å¯è¯æˆæƒï¼Œæœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜… [LICENSE](LICENSE) æ–‡ä»¶ã€‚


## ğŸš§ References

+ [ChatGLM: An Open Bilingual Dialogue Language Model](https://github.com/THUDM/ChatGLM-6B)

+ [BLOOM: A 176B-Parameter Open-Access Multilingual Language Model](https://arxiv.org/abs/2211.05100)

+ [LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/abs/2302.13971v1)

+ [Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca](https://github.com/ymcui/Chinese-LLaMA-Alpaca)

+ [Phoenix: Democratizing ChatGPT across Languages](https://github.com/FreedomIntelligence/LLMZoo)

+ [MOSS: An open-sourced plugin-augmented conversational language model](https://github.com/OpenLMLab/MOSS)

+ [FastChat: An open platform for training, serving, and evaluating large language model based chatbots](https://github.com/lm-sys/FastChat)

+ [LangChain: Building applications with LLMs through composability](https://github.com/hwchase17/langchain)

+ [ChuanhuChatgpt](https://github.com/GaiZhenbiao/ChuanhuChatGPT)


## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=xusenlinzy/api-for-open-llm&type=Date)](https://star-history.com/#xusenlinzy/api-for-open-llm&Date)
